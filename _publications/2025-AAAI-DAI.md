---
title: 'From Explainability to Interpretability: Interpretable Policies in Reinforcement Learning Via Model Explanation'
collection: publications
permalink: /publication/2025-AAAI-DAI
date: 2024-12-20
venue: 'Deployable AI Workshop @ AAAI 2025'
paperurl: ' '
citation: 'Li, Peilang, Umer Siddique, and Yongcan Cao. "From Explainability to Interpretability: Interpretable Policies in Reinforcement Learning Via Model Explanation." Deployable AI Workshop @ AAAI. 2025.'
---

Deep reinforcement learning (RL) has shown remarkable success in complex domains, however, the inherent black box nature of deep neural network policies raises significant challenges in understanding and trusting the decision-making processes. While existing explainable RL methods provide local insights, they fail to deliver global understanding of the model, particularly in high-stakes applications. To overcome this limitation, we propose a novel model-agnostic approach that bridges the gap between explainability and interpretability by leveraging Shapley values to transform complex deep RL policies into transparent representations. The proposed approach offers two key contributions: a novel approach employing Shapley values to policy interpretation that goes beyond local explanations, and general framework applicable to both off-policy and on-policy algorithms.  We evaluate our approach with three existing deep RL algorithms and validate its performance in two classic control environments. The results demonstrate that our approach not only preserves the original models' effectiveness but also generates more stable interpretable policies. [Download paper here](https://arxiv.org/pdf/2501.09858)