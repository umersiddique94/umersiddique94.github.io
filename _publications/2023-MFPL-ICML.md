---
title: Fairness in Preference-based Reinforcement Learning
collection: publications
permalink: /publication/2023-MFPL-ICML
date: 2023-05-01
venue: 'MFPL @ International Conference on Machine Learning'
paperurl: 'https://arxiv.org/pdf/2306.09995'
citation: 'Siddique, Umer, Abhinav Sinha, and Yongcan Cao. "Fairness in Preference-based Reinforcement Learning." ICML 2023 Workshop The Many Facets of Preference-Based Learning. 2023.'
---

In this paper, we address the issue of fairness in preference-based reinforcement learning (PbRL) in the presence of multiple objectives. The main objective is to design control policies that can optimize multiple objectives while treating each objective fairly. Toward this objective, we design a new fairness-induced preference-based reinforcement learning or FPbRL. The main idea of FPbRL is to learn vector reward functions associated with multiple objectives via new welfare-based preferences rather than reward-based preference in PbRL, coupled with policy learning via maximizing a generalized Gini welfare function. Finally, we provide experiment studies on three different environments to show that the proposed FPbRL approach can achieve both efficiency and equity for learning effective and fair policies. [Download paper here](https://arxiv.org/pdf/2306.09995)
